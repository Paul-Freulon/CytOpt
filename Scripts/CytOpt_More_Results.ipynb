{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More results on the HIPC data with CytOpt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we estimate the class proportions in every data set of the HIPC data set using the data set Stanford1A as a source data set. We inform the reader that estimating the class proportions for the 61 data sets could last up to 2 hours. Instead of running this notebook, one can use the estimation results provided in the file `Res_Estimation_Stan1A.txt` and display those results with the notebook `Bland_Altman_Full_Target_HIPC`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import sys\n",
    "sys.path.append(\"../Functions\")\n",
    "from Tools_CytOpt_Descent_Ascent import *\n",
    "from Tools_CytOpt_MinMax_Swapping import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting of the seed.\n",
    "np.random.seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Patient 1 replicate A \n",
    "\n",
    "Stanford1A_values = pd.read_csv('../Data/W2_1_values.csv',\n",
    "                                 usecols = np.arange(1,8))\n",
    "Stanford1A_clust = pd.read_csv('../Data/W2_1_clust.csv',\n",
    "                                usecols = [1])\n",
    "Yale1A_values = pd.read_csv('../Data/FTV_1_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Yale1A_clust = pd.read_csv('../Data/FTV_1_clust.csv',\n",
    "                           usecols = [1])\n",
    "Ucla1A_values = pd.read_csv('../Data/IU_1_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Ucla1A_clust = pd.read_csv('../Data/IU_1_clust.csv',\n",
    "                           usecols = [1])\n",
    "Nhlbi1A_values = pd.read_csv('../Data/D54_1_values.csv',\n",
    "                             usecols = np.arange(1,8))\n",
    "Nhlbi1A_clust = pd.read_csv('../Data/D54_1_clust.csv',\n",
    "                            usecols = [1])\n",
    "Cimr1A_values = pd.read_csv('../Data/O0_1_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Cimr1A_clust = pd.read_csv('../Data/O0_1_clust.csv',\n",
    "                           usecols = [1])\n",
    "Baylor1A_values = pd.read_csv('../Data/pw_2_values.csv',\n",
    "                              usecols = np.arange(1,8))\n",
    "Baylor1A_clust = pd.read_csv('../Data/pw_2_clust.csv',\n",
    "                             usecols = [1])\n",
    "Miami1A_values = pd.read_csv('../Data/pM_1_values.csv', \n",
    "                             usecols = np.arange(1,8))\n",
    "Miami1A_clust = pd.read_csv('../Data/pM_1_clust.csv',\n",
    "                            usecols = [1])\n",
    "\n",
    "#Patient 1 replicate 2\n",
    "\n",
    "Stanford1B_values = pd.read_csv('../Data/W2_2_values.csv',\n",
    "                                 usecols = np.arange(1,8))\n",
    "Stanford1B_clust = pd.read_csv('../Data/W2_2_clust.csv',\n",
    "                                usecols = [1])\n",
    "Yale1B_values = pd.read_csv('../Data/FTV_2_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Yale1B_clust = pd.read_csv('../Data/FTV_2_clust.csv',\n",
    "                           usecols = [1])\n",
    "Ucla1B_values = pd.read_csv('../Data/IU_2_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Ucla1B_clust = pd.read_csv('../Data/IU_2_clust.csv',\n",
    "                           usecols = [1])\n",
    "Nhlbi1B_values = pd.read_csv('../Data/D54_2_values.csv',\n",
    "                             usecols = np.arange(1,8))\n",
    "Nhlbi1B_clust = pd.read_csv('../Data/D54_2_clust.csv',\n",
    "                            usecols = [1])\n",
    "Cimr1B_values = pd.read_csv('../Data/O0_2_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Cimr1B_clust = pd.read_csv('../Data/O0_2_clust.csv',\n",
    "                           usecols = [1])\n",
    "Baylor1B_values = pd.read_csv('../Data/pw_2_values.csv',\n",
    "                              usecols = np.arange(1,8))\n",
    "Baylor1B_clust = pd.read_csv('../Data/pw_2_clust.csv',\n",
    "                             usecols = [1])\n",
    "Miami1B_values = pd.read_csv('../Data/pM_2_values.csv', \n",
    "                             usecols = np.arange(1,8))\n",
    "Miami1B_clust = pd.read_csv('../Data/pM_2_clust.csv',\n",
    "                            usecols = [1])\n",
    "\n",
    "#Patient 1 replicate 3 \n",
    "\n",
    "Stanford1C_values = pd.read_csv('../Data/W2_3_values.csv',\n",
    "                                 usecols = np.arange(1,8))\n",
    "Stanford1C_clust = pd.read_csv('../Data/W2_3_clust.csv',\n",
    "                                usecols = [1])\n",
    "Yale1C_values = pd.read_csv('../Data/FTV_3_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Yale1C_clust = pd.read_csv('../Data/FTV_3_clust.csv',\n",
    "                           usecols = [1])\n",
    "Ucla1C_values = pd.read_csv('../Data/IU_3_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Ucla1C_clust = pd.read_csv('../Data/IU_3_clust.csv',\n",
    "                           usecols = [1])\n",
    "Nhlbi1C_values = pd.read_csv('../Data/D54_3_values.csv',\n",
    "                             usecols = np.arange(1,8))\n",
    "Nhlbi1C_clust = pd.read_csv('../Data/D54_3_clust.csv',\n",
    "                            usecols = [1])\n",
    "Cimr1C_values = pd.read_csv('../Data/O0_3_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Cimr1C_clust = pd.read_csv('../Data/O0_3_clust.csv',\n",
    "                           usecols = [1])\n",
    "Baylor1C_values = pd.read_csv('../Data/pw_3_values.csv',\n",
    "                              usecols = np.arange(1,8))\n",
    "Baylor1C_clust = pd.read_csv('../Data/pw_3_clust.csv',\n",
    "                             usecols = [1])\n",
    "Miami1C_values = pd.read_csv('../Data/pM_3_values.csv', \n",
    "                             usecols = np.arange(1,8))\n",
    "Miami1C_clust = pd.read_csv('../Data/pM_3_clust.csv',\n",
    "                            usecols = [1])\n",
    "\n",
    "#Patient 2 replicate 1\n",
    "\n",
    "Stanford2A_values = pd.read_csv('../Data/W2_4_values.csv',\n",
    "                                 usecols = np.arange(1,8))\n",
    "Stanford2A_clust = pd.read_csv('../Data/W2_4_clust.csv',\n",
    "                                usecols = [1])\n",
    "Yale2A_values = pd.read_csv('../Data/FTV_4_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Yale2A_clust = pd.read_csv('../Data/FTV_4_clust.csv',\n",
    "                           usecols = [1])\n",
    "Ucla2A_values = pd.read_csv('../Data/IU_4_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Ucla2A_clust = pd.read_csv('../Data/IU_4_clust.csv',\n",
    "                           usecols = [1])\n",
    "Nhlbi2A_values = pd.read_csv('../Data/D54_4_values.csv',\n",
    "                             usecols = np.arange(1,8)) \n",
    "Nhlbi2A_clust = pd.read_csv('../Data/D54_4_clust.csv',\n",
    "                            usecols = [1])\n",
    "Cimr2A_values = pd.read_csv('../Data/O0_4_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Cimr2A_clust = pd.read_csv('../Data/O0_4_clust.csv',\n",
    "                           usecols = [1])\n",
    "Baylor2A_values = pd.read_csv('../Data/pw_4_values.csv',\n",
    "                              usecols = np.arange(1,8))\n",
    "Baylor2A_clust = pd.read_csv('../Data/pw_4_clust.csv',\n",
    "                             usecols = [1])\n",
    "Miami2A_values = pd.read_csv('../Data/pM_4_values.csv', \n",
    "                             usecols = np.arange(1,8))\n",
    "Miami2A_clust = pd.read_csv('../Data/pM_4_clust.csv',\n",
    "                            usecols = [1])\n",
    "\n",
    "#Patient 2 replicate 2\n",
    "\n",
    "Stanford2B_values = pd.read_csv('../Data/W2_5_values.csv',\n",
    "                                 usecols = np.arange(1,8))\n",
    "Stanford2B_clust = pd.read_csv('../Data/W2_5_clust.csv',\n",
    "                                usecols = [1])\n",
    "Yale2B_values = pd.read_csv('../Data/FTV_5_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Yale2B_clust = pd.read_csv('../Data/FTV_5_clust.csv',\n",
    "                           usecols = [1])\n",
    "Ucla2B_values = pd.read_csv('../Data/IU_5_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Ucla2B_clust = pd.read_csv('../Data/IU_5_clust.csv',\n",
    "                           usecols = [1])\n",
    "Nhlbi2B_values = pd.read_csv('../Data/D54_5_values.csv',\n",
    "                             usecols = np.arange(1,8)) \n",
    "Nhlbi2B_clust = pd.read_csv('../Data/D54_5_clust.csv',\n",
    "                            usecols = [1])\n",
    "Cimr2B_values = pd.read_csv('../Data/O0_5_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Cimr2B_clust = pd.read_csv('../Data/O0_5_clust.csv',\n",
    "                           usecols = [1])\n",
    "Baylor2B_values = pd.read_csv('../Data/pw_5_values.csv',\n",
    "                              usecols = np.arange(1,8))\n",
    "Baylor2B_clust = pd.read_csv('../Data/pw_5_clust.csv',\n",
    "                             usecols = [1])\n",
    "Miami2B_values = pd.read_csv('../Data/pM_5_values.csv', \n",
    "                             usecols = np.arange(1,8))\n",
    "Miami2B_clust = pd.read_csv('../Data/pM_5_clust.csv',\n",
    "                            usecols = [1])\n",
    "\n",
    "#Patient 2 replicate 3\n",
    "\n",
    "Stanford2C_values = pd.read_csv('../Data/W2_6_values.csv',\n",
    "                                 usecols = np.arange(1,8))\n",
    "Stanford2C_clust = pd.read_csv('../Data/W2_6_clust.csv',\n",
    "                                usecols = [1])\n",
    "Yale2C_values = pd.read_csv('../Data/FTV_6_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Yale2C_clust = pd.read_csv('../Data/FTV_6_clust.csv',\n",
    "                           usecols = [1])\n",
    "Ucla2C_values = pd.read_csv('../Data/IU_6_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Ucla2C_clust = pd.read_csv('../Data/IU_6_clust.csv',\n",
    "                           usecols = [1])\n",
    "Nhlbi2C_values = pd.read_csv('../Data/D54_6_values.csv',\n",
    "                             usecols = np.arange(1,8)) \n",
    "Nhlbi2C_clust = pd.read_csv('../Data/D54_6_clust.csv',\n",
    "                            usecols = [1])\n",
    "Cimr2C_values = pd.read_csv('../Data/O0_6_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Cimr2C_clust = pd.read_csv('../Data/O0_6_clust.csv',\n",
    "                           usecols = [1])\n",
    "Baylor2C_values = pd.read_csv('../Data/pw_6_values.csv',\n",
    "                              usecols = np.arange(1,8))\n",
    "Baylor2C_clust = pd.read_csv('../Data/pw_6_clust.csv',\n",
    "                             usecols = [1])\n",
    "Miami2C_values = pd.read_csv('../Data/pM_6_values.csv', \n",
    "                             usecols = np.arange(1,8))\n",
    "Miami2C_clust = pd.read_csv('../Data/pM_6_clust.csv',\n",
    "                            usecols = [1])\n",
    "\n",
    "#Patient 3 replicate 1\n",
    "\n",
    "Stanford3A_values = pd.read_csv('../Data/W2_7_values.csv',\n",
    "                                 usecols = np.arange(1,8))\n",
    "Stanford3A_clust = pd.read_csv('../Data/W2_7_clust.csv',\n",
    "                                usecols = [1])\n",
    "Yale3A_values = pd.read_csv('../Data/FTV_7_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Yale3A_clust = pd.read_csv('../Data/FTV_7_clust.csv',\n",
    "                           usecols = [1])\n",
    "Ucla3A_values = pd.read_csv('../Data/IU_7_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Ucla3A_clust = pd.read_csv('../Data/IU_7_clust.csv',\n",
    "                           usecols = [1])\n",
    "Nhlbi3A_values = pd.read_csv('../Data/D54_7_values.csv',\n",
    "                             usecols = np.arange(1,8))\n",
    "Nhlbi3A_clust = pd.read_csv('../Data/D54_7_clust.csv',\n",
    "                            usecols = [1])\n",
    "Cimr3A_values = pd.read_csv('../Data/O0_7_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Cimr3A_clust = pd.read_csv('../Data/O0_7_clust.csv',\n",
    "                           usecols = [1])\n",
    "Baylor3A_values = pd.read_csv('../Data/pw_7_values.csv',\n",
    "                              usecols = np.arange(1,8))\n",
    "Baylor3A_clust = pd.read_csv('../Data/pw_7_clust.csv',\n",
    "                             usecols = [1])\n",
    "Miami3A_values = pd.read_csv('../Data/pM_7_values.csv', \n",
    "                             usecols = np.arange(1,8))\n",
    "Miami3A_clust = pd.read_csv('../Data/pM_7_clust.csv',\n",
    "                            usecols = [1])\n",
    "\n",
    "#Patient 3 replicate 2\n",
    "\n",
    "Stanford3B_values = pd.read_csv('../Data/W2_8_values.csv',\n",
    "                                 usecols = np.arange(1,8))\n",
    "Stanford3B_clust = pd.read_csv('../Data/W2_8_clust.csv',\n",
    "                                usecols = [1])\n",
    "Yale3B_values = pd.read_csv('../Data/FTV_8_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Yale3B_clust = pd.read_csv('../Data/FTV_8_clust.csv',\n",
    "                           usecols = [1])\n",
    "Ucla3B_values = pd.read_csv('../Data/IU_8_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Ucla3B_clust = pd.read_csv('../Data/IU_8_clust.csv',\n",
    "                           usecols = [1])\n",
    "Nhlbi3B_values = pd.read_csv('../Data/D54_8_values.csv',\n",
    "                             usecols = np.arange(1,8))\n",
    "Nhlbi3B_clust = pd.read_csv('../Data/D54_8_clust.csv',\n",
    "                            usecols = [1])\n",
    "Cimr3B_values = pd.read_csv('../Data/O0_8_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Cimr3B_clust = pd.read_csv('../Data/O0_8_clust.csv',\n",
    "                           usecols = [1])\n",
    "Baylor3B_values = pd.read_csv('../Data/pw_8_values.csv',\n",
    "                              usecols = np.arange(1,8))\n",
    "Baylor3B_clust = pd.read_csv('../Data/pw_8_clust.csv',\n",
    "                             usecols = [1])\n",
    "Miami3B_values = pd.read_csv('../Data/pM_8_values.csv', \n",
    "                             usecols = np.arange(1,8))\n",
    "Miami3B_clust = pd.read_csv('../Data/pM_8_clust.csv',\n",
    "                            usecols = [1])\n",
    "\n",
    "#Patient 3 replicate 3\n",
    "\n",
    "Stanford3C_values = pd.read_csv('../Data/W2_9_values.csv',\n",
    "                                 usecols = np.arange(1,8))\n",
    "Stanford3C_clust = pd.read_csv('../Data/W2_9_clust.csv',\n",
    "                                usecols = [1])\n",
    "Yale3C_values = pd.read_csv('../Data/FTV_9_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Yale3C_clust = pd.read_csv('../Data/FTV_9_clust.csv',\n",
    "                           usecols = [1])\n",
    "Ucla3C_values = pd.read_csv('../Data/IU_9_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Ucla3C_clust = pd.read_csv('../Data/IU_9_clust.csv',\n",
    "                           usecols = [1])\n",
    "Nhlbi3C_values = pd.read_csv('../Data/D54_9_values.csv',\n",
    "                             usecols = np.arange(1,8))\n",
    "Nhlbi3C_clust = pd.read_csv('../Data/D54_9_clust.csv',\n",
    "                            usecols = [1])\n",
    "Cimr3C_values = pd.read_csv('../Data/O0_9_values.csv',\n",
    "                            usecols = np.arange(1,8))\n",
    "Cimr3C_clust = pd.read_csv('../Data/O0_9_clust.csv',\n",
    "                           usecols = [1])\n",
    "Baylor3C_values = pd.read_csv('../Data/pw_9_values.csv',\n",
    "                              usecols = np.arange(1,8))\n",
    "Baylor3C_clust = pd.read_csv('../Data/pw_9_clust.csv',\n",
    "                             usecols = [1])\n",
    "Miami3C_values = pd.read_csv('../Data/pM_9_values.csv', \n",
    "                             usecols = np.arange(1,8))\n",
    "Miami3C_clust = pd.read_csv('../Data/pM_9_clust.csv',\n",
    "                            usecols = [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Target = [Stanford1A_values, Yale1A_values, Ucla1A_values,\n",
    "    Nhlbi1A_values, Cimr1A_values, Baylor1A_values, Miami1A_values,\n",
    "              Stanford2A_values, Yale2A_values, Ucla2A_values,\n",
    "    Nhlbi2A_values, Cimr2A_values, Baylor2A_values, Miami2A_values,\n",
    "              Stanford3A_values, Yale3A_values, Ucla3A_values,\n",
    "    Nhlbi3A_values, Cimr3A_values, Baylor3A_values, Miami3A_values,\n",
    "              Stanford1B_values, Yale1B_values, Ucla1B_values,\n",
    "    Nhlbi1B_values, Cimr1B_values, Baylor1B_values, Miami1B_values,\n",
    "              Stanford2B_values, Yale2B_values, Ucla2B_values,\n",
    "    Nhlbi2B_values, Cimr2B_values, Baylor2B_values, Miami2B_values,\n",
    "              Stanford3B_values, Yale3B_values, Ucla3B_values,\n",
    "    Nhlbi3B_values, Cimr3B_values, Baylor3B_values, Miami3B_values,\n",
    "              Stanford1C_values, Yale1C_values, Ucla1C_values,\n",
    "    Nhlbi1C_values, Cimr1C_values, Baylor1C_values, Miami1C_values,\n",
    "              Stanford2C_values, Yale2C_values, Ucla2C_values,\n",
    "    Nhlbi2C_values, Cimr2C_values, Baylor2C_values, Miami2C_values,\n",
    "              Stanford3C_values, Yale3C_values, Ucla3C_values,\n",
    "    Nhlbi3C_values, Cimr3C_values, Baylor3C_values, Miami3C_values]\n",
    "    \n",
    "\n",
    "Label_Target = [Stanford1A_clust, Yale1A_clust, Ucla1A_clust,\n",
    "    Nhlbi1A_clust, Cimr1A_clust, Baylor1A_clust, Miami1A_clust,\n",
    "              Stanford2A_clust, Yale2A_clust, Ucla2A_clust,\n",
    "    Nhlbi2A_clust, Cimr2A_clust, Baylor2A_clust, Miami2A_clust,\n",
    "              Stanford3A_clust, Yale3A_clust, Ucla3A_clust,\n",
    "    Nhlbi3A_clust, Cimr3A_clust, Baylor3A_clust, Miami3A_clust,\n",
    "              Stanford1B_clust, Yale1B_clust, Ucla1B_clust,\n",
    "    Nhlbi1B_clust, Cimr1B_clust, Baylor1B_clust, Miami1B_clust,\n",
    "              Stanford2B_clust, Yale2B_clust, Ucla2B_clust,\n",
    "    Nhlbi2B_clust, Cimr2B_clust, Baylor2B_clust, Miami2B_clust,\n",
    "              Stanford3B_clust, Yale3B_clust, Ucla3B_clust,\n",
    "    Nhlbi3B_clust, Cimr3B_clust, Baylor3B_clust, Miami3B_clust,\n",
    "              Stanford1C_clust, Yale1C_clust, Ucla1C_clust,\n",
    "    Nhlbi1C_clust, Cimr1C_clust, Baylor1C_clust, Miami1C_clust,\n",
    "              Stanford2C_clust, Yale2C_clust, Ucla2C_clust,\n",
    "    Nhlbi2C_clust, Cimr2C_clust, Baylor2C_clust, Miami2C_clust,\n",
    "              Stanford3C_clust, Yale3C_clust, Ucla3C_clust,\n",
    "    Nhlbi3C_clust, Cimr3C_clust, Baylor3C_clust, Miami3C_clust]\n",
    "\n",
    "\n",
    "Names = ['Stanford1A', 'Yale1A', 'Ucla1A', 'Nhlbi1A', 'Cimr1A', 'Baylor1A', 'Miami1A',\n",
    "         'Stanford2A', 'Yale2A', 'Ucla2A', 'Nhlbi2A', 'Cimr2A', 'Baylor2A', 'Miami2A',\n",
    "         'Stanford3A', 'Yale3A', 'Ucla3A', 'Nhlbi3A', 'Cimr3A', 'Baylor3A', 'Miami3A',\n",
    "         'Stanford1B', 'Yale1B', 'Ucla1B', 'Nhlbi1B', 'Cimr1B', 'Baylor1B', 'Miami1B',\n",
    "         'Stanford2B', 'Yale2B', 'Ucla2B', 'Nhlbi2B', 'Cimr2B', 'Baylor2B', 'Miami2B',\n",
    "         'Stanford3B', 'Yale3B', 'Ucla3B', 'Nhlbi3B', 'Cimr3B', 'Baylor3B', 'Miami3B',\n",
    "         'Stanford1C', 'Yale1C', 'Ucla1C', 'Nhlbi1C', 'Cimr1C', 'Baylor1C', 'Miami1C',\n",
    "         'Stanford2C', 'Yale2C', 'Ucla2C', 'Nhlbi2C', 'Cimr2C', 'Baylor2C', 'Miami2C',\n",
    "         'Stanford3C', 'Yale3C', 'Ucla3C', 'Nhlbi3C', 'Cimr3C', 'Baylor3C', 'Miami3C']\n",
    "\n",
    "Name_class = ['Classe {}'.format(k+1) for k in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selection of the source data set.\n",
    "#We selected the first data set : Stanford1A\n",
    "d=0\n",
    "\n",
    "Current_Data_Tar = Data_Target.copy()\n",
    "Current_Lab_Tar = Label_Target.copy()\n",
    "Current_Names = Names.copy()\n",
    "\n",
    "del Current_Data_Tar[d]\n",
    "del Current_Lab_Tar[d]\n",
    "del Current_Names[d]\n",
    "\n",
    "#Preprocessing of the source data set\n",
    "X_source = np.asarray(Data_Target[d])\n",
    "X_source = X_source * (X_source > 0)\n",
    "scaler = MinMaxScaler()\n",
    "X_source = scaler.fit_transform(X_source)\n",
    "Lab_source = np.asarray(Label_Target[d]['x'])\n",
    "\n",
    "N = len(Current_Data_Tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting of the parameters for the descent-ascent procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.0001\n",
    "lbd = 0.0001\n",
    "n_iter = 10000\n",
    "step_grad = 5\n",
    "power = 0.99\n",
    "\n",
    "h_hat_storage = np.zeros((N,10))\n",
    "h_true_storage = np.zeros((N,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yale1A\n",
      "Ucla1A\n",
      "Nhlbi1A\n",
      "Cimr1A\n",
      "Baylor1A\n",
      "Miami1A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-07c6892b9720>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#Class proportions estimation with CytOpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     h_hat = cytopt_minmax(X_source, X_tar, Lab_source, eps=eps, lbd=lbd, n_iter=n_iter,\n\u001b[0m\u001b[1;32m     20\u001b[0m                   step=step_grad, power=power, monitoring=False)[0]\n\u001b[1;32m     21\u001b[0m     \u001b[0mh_hat_storage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/Review_CytOpT/CytOpt/Scripts/../Functions/Tools_CytOpt_MinMax_Swapping.py\u001b[0m in \u001b[0;36mcytopt_minmax\u001b[0;34m(X_s, X_t, Lab_source, eps, lbd, n_iter, step, power, theta_true, monitoring)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mgrd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlbd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgrd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/Review_CytOpT/CytOpt/Scripts/../Functions/Tools_CytOpt_MinMax_Swapping.py\u001b[0m in \u001b[0;36mgrad_f\u001b[0;34m(lbd, eps, X_s, X_t, j, u, D)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvec1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0marg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlbd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mcor2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mvec2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcor2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "for it, X_tar, Lab_tar in zip(np.arange(N), Current_Data_Tar, Current_Lab_Tar):\n",
    "    \n",
    "    print(Names[it+1])\n",
    "    #Preprocessing of the target data set.\n",
    "    X_tar = np.asarray(X_tar)\n",
    "    X_tar = X_tar * (X_tar > 0)\n",
    "    X_tar = scaler.fit_transform(X_tar)\n",
    "    \n",
    "    #Computation of the benchmark proportions in the target data set.\n",
    "    Lab_tar = np.asarray(Lab_tar['x'])\n",
    "    h_true = np.zeros(10)\n",
    "    for k in range(10):\n",
    "        h_true[k] = np.sum(Lab_tar == k+1)/len(Lab_tar)\n",
    "    h_true_storage[it,:] = h_true\n",
    "    \n",
    "    #Class proportions estimation with CytOpt\n",
    "    h_hat = cytopt_minmax(X_source, X_tar, Lab_source, eps=eps, lbd=lbd, n_iter=n_iter,\n",
    "                  step=step_grad, power=power, monitoring=False)[0]\n",
    "    h_hat_storage[it,:] = h_hat\n",
    "    \n",
    "elapsed_time = time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'elapsed_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5bd4b8a06a5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Elapsed time :'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melapsed_time\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' Mins'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'elapsed_time' is not defined"
     ]
    }
   ],
   "source": [
    "print('Elapsed time :', elapsed_time/60, ' Mins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storage of the estimation results in dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_hat_data_frame = pd.DataFrame(h_hat_storage,\n",
    "                                columns = ['Classe {}'.format(k+1) for k in range(10)],\n",
    "                                index = Current_Names)\n",
    "\n",
    "h_true_data_frame = pd.DataFrame(h_true_storage, \n",
    "                                columns = ['Classe {}'.format(k+1) for k in range(10)],\n",
    "                                index = Current_Names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Storage of the results in csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_hat_data_frame.to_csv('Res_Estimation_Source_{}.txt'.format(Names[d]))\n",
    "h_true_data_frame.to_csv('True_proportion_Source_{}.txt'.format(Names[d]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
